{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95b3afa-92ac-4b2b-8040-0988e7556206",
   "metadata": {},
   "source": [
    " # Paso 1: Importar las librerías necesarias\n",
    "Comenzamos importando las librerías que utilizaremos en el proceso.\n",
    "pandas y numpy para manipulación de datos.\n",
    "random para selecciones aleatorias.\n",
    "train_test_split de sklearn para dividir los datos.\n",
    "Sequential, Dense de Keras para construir el modelo.\n",
    "Métricas y callbacks para evaluar y optimizar el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2b819d-f518-41c3-82cf-478097069eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Recall, Precision\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b3f6b-917f-4e5a-bcc6-d878bc5f68d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Paso 2: Cargar y preparar los datos\n",
    "## 2.1 Cargar el archivo resultados.csv\n",
    "Este archivo debe contener las columnas ID_Pelicula y ID_Lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4d966-a17e-458c-842b-fc9c3b7af221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo resultados.csv\n",
    "data = pd.read_csv('resultados.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ab756-9281-4ec8-a07c-4164818fa432",
   "metadata": {},
   "source": [
    "## 2.2 Crear un mapeo de películas y listas\n",
    "Creamos:\n",
    "\n",
    "Un conjunto de todos los IDs de películas.\n",
    "Un diccionario que mapea cada ID_Lista a un conjunto de ID_Pelicula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcc0d55-e6c9-4025-9fc5-1e3aaec1cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el conjunto de todos los IDs de películas\n",
    "all_movie_ids = set(data['ID_Pelicula'].astype(str))\n",
    "\n",
    "# Crear un diccionario que mapea ID_Lista a un conjunto de IDs de películas\n",
    "list_to_movies = data.groupby('ID_Lista')['ID_Pelicula'].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47da07f9-e1fb-49f9-a0b7-6f2bfdc95f77",
   "metadata": {},
   "source": [
    "## 2.3 Crear un índice para los IDs de películas\n",
    "Asignamos un índice único a cada película para crear los vectores booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03518655-f036-4b64-8cc5-af70cdf54dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un diccionario que mapea ID_Pelicula a un índice único\n",
    "movie_id_to_index = {movie_id: idx for idx, movie_id in enumerate(all_movie_ids)}\n",
    "index_to_movie_id = {idx: movie_id for movie_id, idx in movie_id_to_index.items()}\n",
    "\n",
    "# Número total de películas\n",
    "num_movies = len(movie_id_to_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef103d-8372-4282-82dd-5eda60164159",
   "metadata": {},
   "source": [
    "# Paso 3: Dividir las listas en entrenamiento y prueba\n",
    "Dividimos las listas (IDs de listas) en conjuntos de entrenamiento y prueba (50% cada uno)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87dca9-7348-4fcd-88ee-a4ac6309c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los IDs de listas\n",
    "all_list_ids = list(list_to_movies.keys())\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "train_list_ids, test_list_ids = train_test_split(all_list_ids, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ebdf5-dfef-4eac-a55a-70d78c5842ae",
   "metadata": {},
   "source": [
    "# Paso 4: Crear los conjuntos de datos X e Y para entrenamiento\n",
    "4.1 Inicializar listas para X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0f8f1-e286-4a7c-8d49-5513fe13b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a4d5d0-edf3-4416-82f4-41ad92c59d0c",
   "metadata": {},
   "source": [
    "## 4.2 Iterar sobre las listas de entrenamiento\n",
    "Para cada lista en el conjunto de entrenamiento:\n",
    "\n",
    "Seleccionar aleatoriamente entre 2 y 5 películas de la lista para el vector de entrada x.\n",
    "Crear el vector de salida y marcando todas las películas de la lista.\n",
    "Agregar x y y a X_train y Y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb3e6a-bb72-44c0-9846-4c9536ab6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for list_id in train_list_ids:\n",
    "    movies_in_list = list(list_to_movies[list_id])\n",
    "    num_movies_in_list = len(movies_in_list)\n",
    "    \n",
    "    if num_movies_in_list < 2:\n",
    "        continue  # Saltar listas con menos de 2 películas\n",
    "    \n",
    "    # Seleccionar aleatoriamente entre 2 y 5 películas para x\n",
    "    num_movies_in_x = min(random.randint(2, 5), num_movies_in_list)\n",
    "    movies_in_x = random.sample(movies_in_list, num_movies_in_x)\n",
    "    \n",
    "    # Crear vector x\n",
    "    x = np.zeros(num_movies)\n",
    "    for movie_id in movies_in_x:\n",
    "        idx = movie_id_to_index[str(movie_id)]\n",
    "        x[idx] = 1\n",
    "    \n",
    "    # Crear vector y\n",
    "    y = np.zeros(num_movies)\n",
    "    for movie_id in movies_in_list:\n",
    "        idx = movie_id_to_index[str(movie_id)]\n",
    "        y[idx] = 1\n",
    "    \n",
    "    # Agregar a los conjuntos de datos\n",
    "    X_train.append(x)\n",
    "    Y_train.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93883159-53d8-45ea-a7c4-65b6cade9da3",
   "metadata": {},
   "source": [
    "# Paso 5: Crear los conjuntos de datos X e Y para prueba\n",
    "Repetimos el mismo proceso para las listas de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a6917-52c1-4dca-bde7-913a7ceebce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "for list_id in test_list_ids:\n",
    "    movies_in_list = list(list_to_movies[list_id])\n",
    "    num_movies_in_list = len(movies_in_list)\n",
    "    \n",
    "    if num_movies_in_list < 2:\n",
    "        continue  # Saltar listas con menos de 2 películas\n",
    "    \n",
    "    # Seleccionar aleatoriamente entre 2 y 5 películas para x\n",
    "    num_movies_in_x = min(random.randint(2, 5), num_movies_in_list)\n",
    "    movies_in_x = random.sample(movies_in_list, num_movies_in_x)\n",
    "    \n",
    "    # Crear vector x\n",
    "    x = np.zeros(num_movies)\n",
    "    for movie_id in movies_in_x:\n",
    "        idx = movie_id_to_index[str(movie_id)]\n",
    "        x[idx] = 1\n",
    "    \n",
    "    # Crear vector y\n",
    "    y = np.zeros(num_movies)\n",
    "    for movie_id in movies_in_list:\n",
    "        idx = movie_id_to_index[str(movie_id)]\n",
    "        y[idx] = 1\n",
    "    \n",
    "    # Agregar a los conjuntos de datos\n",
    "    X_test.append(x)\n",
    "    Y_test.append(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3af5d2-e651-4f42-b93b-725c29825d9a",
   "metadata": {},
   "source": [
    "# Paso 6: Convertir las listas a arrays de NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e6a3b-3dc4-43fa-94f5-215dfed927de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1ef6d-0c3e-4f43-a7e1-d923a8229482",
   "metadata": {},
   "source": [
    "# Paso 7: Construir y entrenar el modelo con Keras\n",
    "## 7.1 Definir el modelo\n",
    "Usaremos un modelo simple de red neuronal con capas densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641dfa0-8c5b-4b7c-970f-01d3575aa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=num_movies))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_movies, activation='sigmoid'))  # Usamos sigmoid para salida multi-etiqueta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0059dd2a-7057-402d-9091-4beb13c373e4",
   "metadata": {},
   "source": [
    "## 7.2 Compilar el modelo\n",
    "Usamos la función de pérdida binary_crossentropy y el optimizador adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52b710f-def5-43cb-b219-938d86221cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ce9943-664c-4b16-994a-e6d4b59423fd",
   "metadata": {},
   "source": [
    "## 7.3 Entrenar el modelo\n",
    "Incluimos EarlyStopping para evitar sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ada08-f41d-4df8-8b03-d69107a9bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516b291-2ad0-402e-bd65-f467f3ed2a52",
   "metadata": {},
   "source": [
    "# Paso 8: Evaluar el modelo en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c0fcc-85ba-4c70-b6ee-cb35b8a6e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy, precision, recall = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b929aa-0d8f-41be-9618-fc8e4d5e864c",
   "metadata": {},
   "source": [
    "# Paso 9: Obtener métricas adicionales\n",
    "Podemos calcular métricas como el F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc3fd2-3ddb-4b20-b9c9-c0d0b1b4036c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "Y_pred_prob = model.predict(X_test)\n",
    "Y_pred = (Y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculamos el F1-score para cada muestra y luego hacemos la media\n",
    "f1 = f1_score(Y_test, Y_pred, average='samples')\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5df38-f312-48b2-93e5-68af42d2a098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
