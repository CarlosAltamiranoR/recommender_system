{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosAltamiranoR/recommender_system/blob/rs_2024/ModeloKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjEz1_5pTx1J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dVoMMuvR8Xf"
      },
      "outputs": [],
      "source": [
        "# Cargar el archivo datos_movies.csv\n",
        "movies_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/movies.csv')\n",
        "\n",
        "# Cargar el archivo datos_movies_list.csv\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/resultados.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df\n"
      ],
      "metadata": {
        "id": "9Hmjp5cu-BhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "lUjwx0-N-W6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Limpieza"
      ],
      "metadata": {
        "id": "v37-a8nFh_ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular el número de películas en cada lista\n",
        "list_sizes = data.groupby('ID_Lista').size()\n",
        "\n",
        "# Mostrar estadísticas descriptivas\n",
        "print(\"Estadísticas de tamaños de listas:\")\n",
        "print(list_sizes.describe())\n"
      ],
      "metadata": {
        "id": "rtA1CBkiiC58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mostrar graficamente distribución"
      ],
      "metadata": {
        "id": "ZSSTB5RWis1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "list_sizes.hist(bins=50)\n",
        "plt.title('Distribución de Tamaños de Listas')\n",
        "plt.xlabel('Número de películas en la lista')\n",
        "plt.ylabel('Número de listas')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UwQfrYfsiNmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un umbral para listas muy cortas (por ejemplo, menos de 2 películas)\n",
        "short_list_threshold = 3\n",
        "\n",
        "# Filtrar listas muy cortas\n",
        "short_lists = list_sizes[list_sizes < short_list_threshold]\n",
        "\n",
        "print(f\"Número de listas con menos de {short_list_threshold} películas: {len(short_lists)}\")\n",
        "print(\"IDs de listas muy cortas:\")\n",
        "print(short_lists.index.tolist())"
      ],
      "metadata": {
        "id": "MPOl777BjMxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar las listas que cumplen con el tamaño mínimo\n",
        "valid_list_ids = list_sizes[list_sizes >= short_list_threshold].index\n",
        "data = data[data['ID_Lista'].isin(valid_list_ids)]"
      ],
      "metadata": {
        "id": "RVZPPAOYjPYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar cuántas veces aparece cada película en las listas\n",
        "movie_counts = data['ID_Pelicula'].value_counts()\n",
        "\n",
        "# Mostrar estadísticas descriptivas\n",
        "print(\"Estadísticas de frecuencias de películas:\")\n",
        "print(movie_counts.describe())"
      ],
      "metadata": {
        "id": "zBu9zD59jTB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "movie_counts.hist(bins=50)\n",
        "plt.title('Distribución de Frecuencias de Películas en Listas')\n",
        "plt.xlabel('Número de apariciones en listas')\n",
        "plt.ylabel('Número de películas')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CGlSqrFIjVNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir un umbral para películas muy frecuentes (por ejemplo, aparecen en más del 5% de las listas)\n",
        "frequency_threshold = data['ID_Lista'].nunique() * 0.05\n",
        "\n",
        "frequent_movies = movie_counts[movie_counts > frequency_threshold]\n",
        "\n",
        "print(f\"Número de películas que aparecen en más del 5% de las listas: {len(frequent_movies)}\")\n",
        "print(\"IDs de películas muy frecuentes:\")\n",
        "print(frequent_movies.index.tolist())"
      ],
      "metadata": {
        "id": "iCkdN7D0jXAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ninguna película aparece en más del 5% de las listas. Es decir, no hay películas que sean extremadamente frecuentes en el conjunto de datos.\n",
        "\n",
        "**Implicaciones**: Dado que no hay películas que aparezcan con tanta frecuencia, el problema de que el modelo recomiende siempre las mismas películas no se debe a que ciertas películas estén sobre-representadas en los datos."
      ],
      "metadata": {
        "id": "YiXJhxOhkDoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar la frecuencia de cada película\n",
        "movie_counts = data['ID_Pelicula'].value_counts()\n",
        "print(movie_counts.head(1000))  # Ver las 10 películas más frecuentes\n"
      ],
      "metadata": {
        "id": "CZMlm2L6pqUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo IA"
      ],
      "metadata": {
        "id": "D_8w3YIujIyU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcbWHAwbR97g"
      },
      "outputs": [],
      "source": [
        "# Obtener el conjunto de IDs de películas presentes en datos_movies_list.csv\n",
        "movie_ids_in_list = set(data['ID_Pelicula'].astype(str))\n",
        "\n",
        "# Filtrar movies_df para que solo contenga películas en movie_ids_in_list\n",
        "movies_df = movies_df[movies_df['id'].astype(str).isin(movie_ids_in_list)].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-2TfANWSCkU"
      },
      "outputs": [],
      "source": [
        "# Convertir IDs a string para consistencia\n",
        "data['ID_Pelicula'] = data['ID_Pelicula'].astype(str)\n",
        "data['ID_Lista'] = data['ID_Lista'].astype(str)\n",
        "\n",
        "# Obtener el conjunto de todos los IDs de películas\n",
        "all_movie_ids = set(data['ID_Pelicula'])\n",
        "\n",
        "# Crear un diccionario que mapea ID_Lista a un conjunto de IDs de películas\n",
        "list_to_movies = data.groupby('ID_Lista')['ID_Pelicula'].apply(set).to_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be5yAg_6SEyW"
      },
      "outputs": [],
      "source": [
        "# Crear un diccionario que mapea ID_Pelicula a un índice único\n",
        "movie_id_to_index = {movie_id: idx for idx, movie_id in enumerate(sorted(all_movie_ids))}\n",
        "index_to_movie_id = {idx: movie_id for movie_id, idx in movie_id_to_index.items()}\n",
        "\n",
        "# Número total de películas\n",
        "num_movies = len(movie_id_to_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1VYrfqTSHBS"
      },
      "outputs": [],
      "source": [
        "# Obtener todos los IDs de listas\n",
        "all_list_ids = list(list_to_movies.keys())\n",
        "\n",
        "# Dividir en entrenamiento y prueba\n",
        "train_list_ids, test_list_ids = train_test_split(all_list_ids, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gv8CdPfSIsF"
      },
      "outputs": [],
      "source": [
        "def create_dataset(list_ids):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for list_id in list_ids:\n",
        "        movies_in_list = list(list_to_movies[list_id])\n",
        "        num_movies_in_list = len(movies_in_list)\n",
        "\n",
        "        if num_movies_in_list < 2:\n",
        "            continue  # Saltar listas con menos de 2 películas\n",
        "\n",
        "        # Seleccionar aleatoriamente entre 2 y 5 películas para x\n",
        "        num_movies_in_x = min(random.randint(1, 5), num_movies_in_list)\n",
        "        movies_in_x = random.sample(movies_in_list, num_movies_in_x)\n",
        "\n",
        "        # Crear vector x\n",
        "        x = np.zeros(num_movies)\n",
        "        for movie_id in movies_in_x:\n",
        "            idx = movie_id_to_index[str(movie_id)]\n",
        "            x[idx] = 1\n",
        "\n",
        "        # Crear vector y\n",
        "        y = np.zeros(num_movies)\n",
        "        for movie_id in movies_in_list:\n",
        "            idx = movie_id_to_index[str(movie_id)]\n",
        "            y[idx] = 1\n",
        "\n",
        "        # Agregar a los conjuntos de datos\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "    return np.array(X), np.array(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InQtp8UCSKoP"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = create_dataset(train_list_ids)\n",
        "X_test, Y_test = create_dataset(test_list_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def binary_focal_loss(gamma=2., alpha=.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "        pt = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
        "        loss = -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt))\n",
        "        return loss\n",
        "    return focal_loss_fixed\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "64ftXTgM49YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos métricas personalizadas"
      ],
      "metadata": {
        "id": "a3oOKiHz7X4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_precision(y_true, y_pred):\n",
        "    y_pred_binary = tf.cast(tf.greater(y_pred, 0.1), tf.float32)\n",
        "    true_positives = tf.reduce_sum(y_true * y_pred_binary)\n",
        "    predicted_positives = tf.reduce_sum(y_pred_binary)\n",
        "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
        "    return precision\n",
        "\n",
        "def custom_recall(y_true, y_pred):\n",
        "    y_pred_binary = tf.cast(tf.greater(y_pred, 0.1), tf.float32)\n",
        "    true_positives = tf.reduce_sum(y_true * y_pred_binary)\n",
        "    possible_positives = tf.reduce_sum(y_true)\n",
        "    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n",
        "    return recall"
      ],
      "metadata": {
        "id": "pS2W_RNG5w0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUQoiiyJSMKL"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Definir el modelo\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(num_movies,)))  # Añadimos una capa de entrada explícita\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(num_movies, activation='sigmoid'))  # Usamos sigmoid para salida multi-etiqueta\n",
        "\n",
        "# Compilar el modelo con Binary Focal Loss\n",
        "#model.compile(optimizer='adam', loss=binary_focal_loss(gamma=2., alpha=.25), metrics=['accuracy'])\n",
        "\n",
        "# Compilar el modelo con Binary Focal Loss con métricas personalizadas\n",
        "model.compile(optimizer='adam',loss=binary_focal_loss(gamma=2., alpha=.25), metrics=['accuracy', custom_precision, custom_recall])\n",
        "\n",
        "# Entrenar el modelo\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=20, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "\n",
        "# Generar predicciones en el conjunto de prueba\n",
        "Y_pred_prob = model.predict(X_test)\n",
        "threshold = 0.1  # Ajustar este valor según sea necesario\n",
        "Y_pred = (Y_pred_prob > threshold).astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parámetros:\n",
        "gamma: Controla el enfoque en las muestras difíciles. Un valor más alto incrementa el enfoque.\n",
        "alpha: Equilibra la importancia entre clases positivas y negativas."
      ],
      "metadata": {
        "id": "f3cMEDnf2rd0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkJmTLB_SOPW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import contextlib\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def suppress_stdout():\n",
        "    with open(os.devnull, \"w\") as devnull:\n",
        "        old_stdout = sys.stdout\n",
        "        sys.stdout = devnull\n",
        "        try:\n",
        "            yield\n",
        "        finally:\n",
        "            sys.stdout = old_stdout\n",
        "\n",
        "def get_recommendations(input_movie_id, top_n=5):\n",
        "    # Crear vector x con una sola película\n",
        "    x = np.zeros(num_movies)\n",
        "    idx = movie_id_to_index[str(input_movie_id)]\n",
        "    x[idx] = 1\n",
        "\n",
        "    # Suprimir la salida estándar durante la predicción\n",
        "    with suppress_stdout():\n",
        "        y_pred_prob = model.predict(np.array([x]))[0]\n",
        "\n",
        "    # Obtener los índices de las top_n predicciones\n",
        "    recommended_indices = np.argsort(y_pred_prob)[::-1]\n",
        "\n",
        "    # Filtrar películas que no sean la película de entrada\n",
        "    recommended_indices = [i for i in recommended_indices if i != idx]\n",
        "\n",
        "    # Obtener los IDs de las películas recomendadas\n",
        "    recommended_movie_ids = [index_to_movie_id[i] for i in recommended_indices[:top_n]]\n",
        "\n",
        "    # Obtener los nombres de las películas recomendadas\n",
        "    recommended_movies = movies_df[movies_df['id'].astype(str).isin(recommended_movie_ids)]\n",
        "\n",
        "    return recommended_movies[['id', 'title']]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_names(movie_ids):\n",
        "    return movies_df[movies_df['id'].astype(str).isin(movie_ids)]['title'].tolist()"
      ],
      "metadata": {
        "id": "PzmcMrezon7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w3W4e44SQSD"
      },
      "outputs": [],
      "source": [
        "# Evaluar las recomendaciones\n",
        "results = []\n",
        "\n",
        "# Limitar el número de listas de prueba\n",
        "max_test_lists = 100\n",
        "test_list_ids_subset = random.sample(test_list_ids, min(max_test_lists, len(test_list_ids)))\n",
        "\n",
        "for list_id in test_list_ids_subset:\n",
        "    movies_in_list = list(list_to_movies[list_id])\n",
        "    num_movies_in_list = len(movies_in_list)\n",
        "\n",
        "    if num_movies_in_list < 3:\n",
        "        continue  # Saltar listas con menos de 3 películas\n",
        "\n",
        "    # Seleccionar una película al azar de la lista\n",
        "    input_movie_id = random.choice(movies_in_list)\n",
        "\n",
        "    # Obtener recomendaciones\n",
        "    recommended_movies = get_recommendations(input_movie_id, top_n=5)\n",
        "\n",
        "    # Obtener los IDs y nombres de las películas recomendadas\n",
        "    recommended_movie_ids = set(recommended_movies['id'].astype(str))\n",
        "    recommended_movie_names = recommended_movies['title'].tolist()\n",
        "\n",
        "    # Películas correctas (que están en la misma lista)\n",
        "    actual_movie_ids = set(movies_in_list)\n",
        "    #actual_movie_ids.discard(input_movie_id)  # Excluir la película de entrada\n",
        "\n",
        "    # Contar cuántas recomendaciones están en la misma lista\n",
        "    correct_recommendations = recommended_movie_ids.intersection(actual_movie_ids)\n",
        "    num_correct = len(correct_recommendations)\n",
        "    correct_recommendation_names = get_movie_names(correct_recommendations)\n",
        "\n",
        "    # Porcentaje de acierto\n",
        "    possible_correct = min(5, len(actual_movie_ids))\n",
        "    hit_percentage = num_correct / possible_correct if possible_correct > 0 else 0\n",
        "\n",
        "    # Guardar resultados\n",
        "    results.append({\n",
        "        'ID_Lista': list_id,\n",
        "        'Película_Entrada_ID': input_movie_id,\n",
        "        'Película_Entrada_Nombre': movies_df[movies_df['id'].astype(str) == input_movie_id]['title'].values[0],\n",
        "        'Recomendaciones_IDs': list(recommended_movie_ids),\n",
        "        'Recomendaciones_Nombres': recommended_movie_names,\n",
        "        'Películas_Correctas_IDs': list(actual_movie_ids),\n",
        "        'Películas_Correctas_Nombres': get_movie_names(actual_movie_ids),\n",
        "        'Aciertos_Nombres': correct_recommendation_names,\n",
        "        'Aciertos': num_correct,\n",
        "        'Posibles_Aciertos': possible_correct,\n",
        "        'Porcentaje_Acierto': hit_percentage\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analizar resultados"
      ],
      "metadata": {
        "id": "3vtWm-X6nUnQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPSAEymQSUGd"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Calcular el porcentaje medio de aciertos\n",
        "mean_hit_percentage = results_df['Porcentaje_Acierto'].mean()\n",
        "print(f\"Porcentaje medio de aciertos: {mean_hit_percentage:.2%}\")\n",
        "\n",
        "# Mostrar algunos resultados\n",
        "results_df[['Película_Entrada_Nombre', 'Recomendaciones_Nombres', 'Aciertos_Nombres', 'Porcentaje_Acierto']].head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# analisis detallado"
      ],
      "metadata": {
        "id": "qCWirCLn0nh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proporción de etiquetas positivas en Y_train\n",
        "positive_ratio = np.sum(Y_train) / (Y_train.shape[0] * Y_train.shape[1])\n",
        "print(f\"Proporción de etiquetas positivas en Y_train: {positive_ratio:.6f}\")\n",
        "\n",
        "# Proporción de etiquetas positivas en Y_test\n",
        "positive_ratio_test = np.sum(Y_test) / (Y_test.shape[0] * Y_test.shape[1])\n",
        "print(f\"Proporción de etiquetas positivas en Y_test: {positive_ratio_test:.6f}\")\n"
      ],
      "metadata": {
        "id": "zwVFxVQr0l4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretación:\n",
        "\n",
        "Si la proporción es muy baja (por ejemplo, menos del 0.1%), indica que las etiquetas son extremadamente esparsas.\n",
        "Esto dificulta que el modelo aprenda, ya que hay muy pocas muestras positivas.\n",
        "Solución:\n",
        "\n",
        "Cambiar la función de pérdida a Kullback-Leibler Divergence ('kullback_leibler_divergence') o Binary Focal Loss que manejan mejor la esparsidad.\n",
        "Ajustar los pesos de clase para penalizar más los errores en clases minoritarias."
      ],
      "metadata": {
        "id": "3FVt3jgm0wcN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sp9AsMZj0_41"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aNma2WhrGojSPEgWKHpYOaC6bVQMCuUY",
      "authorship_tag": "ABX9TyPF5W0gAcwNROef+nVAnanZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}